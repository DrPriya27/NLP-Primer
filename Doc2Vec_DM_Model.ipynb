{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d110bb",
   "metadata": {},
   "source": [
    "# Doc2Vec: Distributed Memory (DM) Model\n",
    "\n",
    "This notebook demonstrates how to train a Doc2Vec model using the Distributed Memory (DM) architecture on a sample corpus. You will learn how to tag documents, build vocabulary, train the model, and retrieve document vectors and similarities.\n",
    "\n",
    "**Outline:**\n",
    "- Introduction to Doc2Vec DM\n",
    "- Tagging documents\n",
    "- Building vocabulary\n",
    "- Training the DM model\n",
    "- Extracting document vectors\n",
    "- Finding most similar documents\n",
    "\n",
    "**References:**\n",
    "- [Doc2Vec Paper](https://arxiv.org/pdf/1405.4053.pdf)\n",
    "- [Gensim Doc2Vec Documentation](https://radimrehurek.com/gensim/models/doc2vec.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ca711",
   "metadata": {},
   "source": [
    "## What is Doc2Vec DM?\n",
    "\n",
    "Doc2Vec DM (Distributed Memory) is an extension of Word2Vec for learning vector representations of documents. The DM model predicts a target word using both context words and a unique document id, allowing the document vector to act as a memory for additional context.\n",
    "\n",
    "**Workflow:**\n",
    "1. Tag each document with a unique id.\n",
    "2. Tokenize the documents.\n",
    "3. Build the vocabulary.\n",
    "4. Train the DM model.\n",
    "5. Extract document vectors and find similar documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1709ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import nltk\n",
    "import os\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    'The quick brown fox jumps over the lazy dog',\n",
    "    'Never jump over the lazy dog quickly',\n",
    "    'A fox is quick and brown',\n",
    "    'Dogs and foxes are animals',\n",
    "    'Foxes are clever and quick',\n",
    "    'Dogs are loyal and friendly'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b864f5d",
   "metadata": {},
   "source": [
    "## Tagging and Tokenizing Documents\n",
    "\n",
    "Each document is tagged with a unique id and tokenized for training. This step prepares the data for the Doc2Vec model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag and tokenize documents\n",
    "# Each document is tagged with a unique id\n",
    "# TaggedDocument(words, [tag])\n",
    "tagged_data = [TaggedDocument(words=nltk.word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(corpus)]\n",
    "print('Tagged and tokenized documents:', tagged_data[:2])  # Show first two for illustration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82faf59e",
   "metadata": {},
   "source": [
    "## Building Vocabulary and Initializing DM Model\n",
    "\n",
    "Build the vocabulary from the tagged data and initialize the Doc2Vec DM model with chosen parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary and initialize DM model\n",
    "vector_size = 50\n",
    "window = 2\n",
    "min_count = 1\n",
    "workers = 1\n",
    "epochs = 40\n",
    "seed = 42\n",
    "dm = 1  # Distributed Memory\n",
    "\n",
    "doc2vec_dm = Doc2Vec(vector_size=vector_size, window=window, min_count=min_count, workers=workers, epochs=epochs, seed=seed, dm=dm)\n",
    "doc2vec_dm.build_vocab(tagged_data)\n",
    "print('Vocabulary size:', len(doc2vec_dm.wv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feea14f",
   "metadata": {},
   "source": [
    "## Training the Doc2Vec DM Model\n",
    "\n",
    "Train the Doc2Vec DM model on the tagged and tokenized corpus. This step learns document and word vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the DM model\n",
    "doc2vec_dm.train(tagged_data, total_examples=doc2vec_dm.corpus_count, epochs=doc2vec_dm.epochs)\n",
    "print('Model trained.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd381711",
   "metadata": {},
   "source": [
    "## Extracting Document Vectors and Finding Similar Documents\n",
    "\n",
    "After training, you can extract the vector for any document and find the most similar documents in the corpus using cosine similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract vector for the first document and find most similar documents\n",
    "first_doc_tag = '0'\n",
    "vector = doc2vec_dm.dv[first_doc_tag]\n",
    "print('Vector for first document:', vector)\n",
    "\n",
    "similar_docs = doc2vec_dm.dv.most_similar(first_doc_tag)\n",
    "print('Most similar documents to first document:', similar_docs)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
